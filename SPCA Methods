#Libraries required for the following code

library(stats)
library(pls)
library(ManifoldOptim)
library(pracma)
library(caret)  
library(MASS)
library(superpc)

#The following assumes that training and test datasets are available. Assuming the dataset is saved in R as data where the first column is the response and the rest the data, the following
#template can be used for pre-processing the data before applying the SPCA methods.

n <- nrow(data)
train_indices <- sample(1:n, size = 0.8 * n)
training_data <- data[train_indices,]
testing_data <- data[-train_indices,]
X_train <- training_data[,-1]
Y_train <- training_data[,1]
X_test <- testing_data[,-1]
Y_test <- testing_data[,1]
train_means <- apply(X_train, 2, mean)
train_stds <- apply(X_train, 2, sd)
X_train <- sweep(X_train, 2, train_means, FUN = "-")
X_train <- sweep(X_train, 2, train_stds, FUN = "/")
X_test <- sweep(X_test, 2, train_means, FUN = "-")
X_test <- sweep(X_test, 2, train_stds, FUN = "/")
X_train <- data.frame(X_train)
X_test <- data.frame(X_test)
y_mean <- mean(Y_train)
y_std <- sd(Y_train)
Y_train <- (Y_train - y_mean) / y_std
Y_test <- (Y_test - y_mean) / y_std


#Code to perform PCR for n_components number of components.

pca_model <- prcomp(X_train, center = FALSE, scale. = FALSE)
      X_train_pca <- as.data.frame(pca_model$x[, 1:n_components])
      X_test_pca <- as.data.frame(predict(pca_model, newdata = X_test)[, 1:n_components])
      
      explained_variance_ratio <- pca_model$sdev^2 / sum(pca_model$sdev^2)
      total_variance_explained_list <- sum(explained_variance_ratio[1:n_components])
      
      PCA_data <- cbind(Y_train, X_train_pca)
      fit1 <- lm(Y_train ~ ., data = PCA_data)
      y_pred <- predict(fit1, newdata = X_test_pca)
      mse_PCA_list <-  mean((Y_test - y_pred)^2)
      
      covXY <- cov(X_train,Y_train)
      covZY <- cov(X_train_pca,Y_train)
      fraction_cov_expl <- sum(covZY^2) / sum(covXY^2)
      covariance_explained_PCR <- fraction_cov_expl


#Code to perform PLS for n_components number of components.

pls_data <- data.frame(y = Y_train, X_train)
      fit_pls <- plsr(y ~ ., data = pls_data, scale = FALSE, validation = "CV")
      variance_explained_pls <- cumsum(explvar(fit_pls))[n_components] / sum(explvar(fit_pls))
      y_pred_pls <- predict(fit_pls, X_test, ncomp = n_components)
      mse_values_pls <- mean((Y_test - y_pred_pls)^2)


#Code to perform SPCA using HSIC for n_components number of components.

rbf_kernel <- function(Y, sigma) { 
      dist_matrix <- as.matrix(dist(Y))
      K <- exp(-dist_matrix^2 / (2 * sigma^2))
      return(K)
}


SPCA_HSIC <- function(X, Y, K, q) {
  C <- t(X) %*% K %*% X
  
  eig <- eigen(C)
  eigenvalues <- eig$values
  eigenvectors <- eig$vectors
  sorted_indices <- order(eigenvalues, decreasing = TRUE)
  eigenvalues <- eigenvalues[sorted_indices]
  eigenvectors <- eigenvectors[, sorted_indices]
  
  W <- eigenvectors[, 1:q]
  
  return(list(W = W, eigenvalues = eigenvalues[1:q]))
}

#Hyperparameter to specify, sigma for the RBF Kernel.

K <- rbf_kernel(Y_train, sigma)
spca_result <- SPCA_HSIC(X_train, Y_train, K, n_components)
W_barshan <- spca_result$W
Z_train_bar <- X_train %*% W_barshan
Z_test_bar <- X_test %*% W_barshan
XtX_train <- t(X_train) %*% X_train
total_variance <- sum(diag(XtX_train))
explained_variance_barshan <- sum(diag(t(W_barshan) %*% XtX_train %*% W_barshan))
fraction_variance_explained_barshan <- explained_variance_barshan / total_variance
variance_explained_barshan <- fraction_variance_explained_barshan
covXY <- cov(X_train,Y_train)
covZY <- cov(Z_train_bar,Y_train)
fraction_cov_expl <- sum(covZY^2) / sum(covXY^2)
covariance_explained_Barshan <- fraction_cov_expl
combined_training_data_barshan <- data.frame(y = Y_train, Z_train_bar)
linear_model_barshan <- lm(y ~ ., data = combined_training_data_barshan)
colnames(Z_test_bar) <- paste0("X", seq_len(ncol(Z_test_bar)))
Y_pred_barshan <- predict(linear_model_barshan, newdata = as.data.frame(Z_test_bar))
mse_values_barshan <- mean((Y_test - Y_pred_barshan)^2)

#Code to perform Bair's method for n_components number of components.

data_train <- list(x = t(X_train), y = Y_train, featurenames = colnames(X_train))
data_test <- list(x = t(X_test), y = Y_test, featurenames = colnames(X_test))
model_bair <- superpc.train(data_train, type = "regression")
feature_scores <- model_bair$feature.scores

#Hyperparameter to specify, threshold, usually using Cross-Validation.
which.features <- (abs(feature_scores) >= threshold) 
X_for_pca <- X_train[,which.features]
pca_result <- prcomp(X_for_pca, center = FALSE, scale. = FALSE)
X_train_bair <- as.data.frame(pca_result$x[, 1:n_components])
X_test_bair <- as.data.frame(predict(pca_result, newdata = X_test)[, 1:n_components])
X_train_bair <- as.matrix(X_train_bair)
XtX_bair <- t(X_train_bair) %*% X_train_bair
var_expl <- sum(diag(XtX_bair))
explained_variance_ratio <- var_expl / total_variance 
variance_explained_bair <- sum(explained_variance_ratio)
X_train_bair <- as.data.frame(X_train_bair)
Bair_data <- cbind(Y_train, X_train_bair)
fit2 <- lm(Y_train ~ ., data = Bair_data)
y_pred_bair <- predict(fit2, newdata = X_test_bair)
mse_values_bair <-  mean((Y_test - y_pred_bair)^2)
covXY <- cov(X_train,Y_train)
covZY <- cov(X_train_bair,Y_train)
fraction_cov_expl <- sum(covZY^2) / sum(covXY^2)
covariance_explained_bair <- fraction_cov_expl


#Code to perfrom LSPCA for n_components number of components.

p <- ncol(X_train)
cost_function <- function(x, X_train, Y_train, q, lambda) {
  L <- matrix(x[1:(p * q)], nrow = p, ncol = q)
  start_index <- p * q + 1
  n <- nrow(Y_train)
  k <- ncol(Y_train)
  w <- matrix(x[start_index:length(x)], nrow = q, ncol = k)
  XL <- X_train %*% L
  lr_resid <- Y_train - (XL %*% w)
  pca_resid <- X_train - (XL %*% t(L))
  lr_obj <- mean(lr_resid^2)
  pca_obj <- mean(pca_resid^2)
  return((lambda * lr_obj) + ((1 - lambda) * pca_obj))
}

L_manifold <- get.grassmann.defn(p, n_components)
w_manifold <- get.euclidean.defn(n_components, ncol(Y_train))
manifold <- get.product.defn(L_manifold, w_manifold)
L_init <- matrix(rnorm(p * n_components), nrow = p, ncol = n_components)
w_init <- matrix(rnorm(n_components * ncol(Y_train)), nrow = n_components, ncol = ncol(Y_train))
params_init <- c(as.vector(L_init), as.vector(w_init))
mod <- Module("ManifoldOptim_module", PACKAGE = "ManifoldOptim")

#Hyperparameter to specify manifold_lambda see Ritchie et al. 2019.
prob <- new(mod$RProblem, function(x) cost_function(x, X_train, Y_train, n_components, manifold_lambda))
solver_params <- get.solver.params(DEBUG = 2)
res <- manifold.optim(prob, manifold, method = "RSD", solver.params = solver_params, x0 = params_init)
xopt <- res$xopt
L_optimized <- matrix(xopt[1:(p * n_components)], nrow = p, ncol = n_components)
w_optimized <- matrix(xopt[(p * n_components + 1):length(xopt)], nrow = n_components, ncol = ncol(Y_train))
Z_train_manifold <- X_train %*% L_optimized
Z_test_manifold <- X_test %*% L_optimized
Y_pred_manifold <- Z_test_manifold %*% w_optimized
covXY <- cov(X_train,Y_train)
covZY <- cov(Z_train_manifold,Y_train)
fraction_cov_expl <- sum(covZY^2) / sum(covXY^2)
covariance_explained_Manifold <- fraction_cov_expl
mse_values_manifold <- mean((Y_test-Y_pred_manifold)^2)
XtX_train_manifold <- t(X_train) %*% X_train
total_variance_manifold <- sum(diag(XtX_train_manifold))
explained_variance_manifold <- sum(diag(t(L_optimized) %*% XtX_train_manifold %*% L_optimized))
fraction_variance_explained_manifold <- explained_variance_manifold / total_variance_manifold
variance_explained_manifold <- fraction_variance_explained_manifold


#Code to perfrom CSPCA for n_components number of components.

CSPCA <- function(X, Y, q, kappa) {
  XtX <- t(X) %*% X  
  XtY <- t(X) %*% Y
  YtX <- t(Y) %*% X
  C <- XtY %*% YtX + kappa * XtX  
  eig <- eigen(C)
  eigenvalues <- eig$values
  eigenvectors <- eig$vectors
  sorted_indices <- order(eigenvalues, decreasing = TRUE)
  eigenvalues <- eigenvalues[sorted_indices]
  eigenvectors <- eigenvectors[, sorted_indices]
  W <- eigenvectors[, 1:q]
  return(list(W = W, eigenvalues = eigenvalues[1:q]))
}

#Hyperparameter to specify kappa. Values in (0.001,0.1) are suggested, otherwise Cross-Validation may be performed depending on the task.
spca_result_supervised <- SCPA(X_train, Y_train, n_components, kappa)
W_supervised <- spca_result_supervised$W
Z_train_supervised <- X_train %*% W_supervised
Z_test_supervised <- X_test %*% W_supervised
XtX_train_supervised <- t(X_train) %*% X_train
total_variance_supervised <- sum(diag(XtX_train_supervised))
explained_variance_supervised <- sum(diag(t(W_supervised) %*% XtX_train_supervised %*% W_supervised))
fraction_variance_explained_supervised <- explained_variance_supervised / total_variance_supervised
variance_explained_supervised <- fraction_variance_explained_supervised
covXY <- cov(X_train,Y_train)
covZY <- cov(Z_train_supervised,Y_train)
fraction_cov_expl <- sum(covZY^2) / sum(covXY^2)
covariance_explained_supervised <- fraction_cov_expl 
combined_training_data_supervised <- data.frame(y = Y_train, Z_train_supervised)
linear_model_supervised <- lm(y ~ ., data = combined_training_data_supervised)
colnames(Z_test_supervised) <- paste0("X", seq_len(ncol(Z_test_supervised)))
Y_pred_supervised <- predict(linear_model_supervised, newdata = as.data.frame(Z_test_supervised))
mse_values_supervised <- mean((Y_test - Y_pred_supervised)^2)
